{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5262bb8",
   "metadata": {},
   "source": [
    "\n",
    "# CausalPilot: Advanced Features and Testing\n",
    "\n",
    "This notebook demonstrates advanced features of CausalPilot and provides a comprehensive testing suite to verify functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import CausalPilot modules\n",
    "import causalpilot as cp\n",
    "from causalpilot.core import CausalGraph, CausalModel\n",
    "from causalpilot.inference import DoubleML, CausalForest, TLearner, SLearner\n",
    "from causalpilot.visualization import plot_causal_graph\n",
    "from causalpilot.utils.testing import generate_synthetic_data\n",
    "from causalpilot.utils.validation import validate_data, validate_graph\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plot style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DifferenceInMeans:\n",
    "    def __init__(self):\n",
    "        self.is_fitted = False\n",
    "        self.individual_effects = None\n",
    "        self.average_effect = None\n",
    "\n",
    "    def fit(self, X, T, Y):\n",
    "        self.X = X\n",
    "        self.T = T\n",
    "        self.Y = Y\n",
    "        self.treated_mean = Y[T == 1].mean()\n",
    "        self.control_mean = Y[T == 0].mean()\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before prediction\")\n",
    "        self.individual_effects = np.full(len(X), self.treated_mean - self.control_mean)\n",
    "        return self.individual_effects\n",
    "\n",
    "    def estimate_effect(self):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before estimating effect\")\n",
    "        self.average_effect = self.treated_mean - self.control_mean\n",
    "        return self.average_effect\n",
    "\n",
    "# Test the custom estimator\n",
    "data_dict = generate_synthetic_data(n_samples=1000, treatment_effect=3.0)\n",
    "custom_data = data_dict['data']\n",
    "true_ate = data_dict['true_ate']\n",
    "feature_names = data_dict['feature_names']\n",
    "\n",
    "dim_estimator = DifferenceInMeans()\n",
    "dim_estimator.fit(custom_data[feature_names], custom_data['treatment'], custom_data['outcome'])\n",
    "dim_effect = dim_estimator.estimate_effect()\n",
    "\n",
    "print(f\"Difference-in-Means estimate: {dim_effect:.4f}\")\n",
    "print(f\"True effect: {true_ate:.4f}\")\n",
    "print(f\"Bias: {dim_effect - true_ate:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc92b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_effect_estimation(X, T, Y, estimator_class, n_bootstrap=100, **kwargs):\n",
    "    n_samples = len(X)\n",
    "    bootstrap_estimates = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "        # Bootstrap sampling\n",
    "        indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        X_boot = X.iloc[indices]\n",
    "        T_boot = T.iloc[indices]\n",
    "        Y_boot = Y.iloc[indices]\n",
    "\n",
    "        # Train estimator\n",
    "        estimator = estimator_class(**kwargs)\n",
    "        estimator.fit(X_boot, T_boot, Y_boot)\n",
    "\n",
    "        # Get estimate\n",
    "        ate = estimator.estimate_effect()\n",
    "        bootstrap_estimates.append(ate)\n",
    "\n",
    "    bootstrap_estimates = np.array(bootstrap_estimates)\n",
    "\n",
    "    return {\n",
    "        'estimates': bootstrap_estimates,\n",
    "        'mean': np.mean(bootstrap_estimates),\n",
    "        'std': np.std(bootstrap_estimates),\n",
    "        'ci_lower': np.percentile(bootstrap_estimates, 2.5),\n",
    "        'ci_upper': np.percentile(bootstrap_estimates, 97.5)\n",
    "    }\n",
    "\n",
    "# Run bootstrap for custom estimator\n",
    "bootstrap_results = bootstrap_effect_estimation(\n",
    "    custom_data[feature_names],\n",
    "    custom_data['treatment'],\n",
    "    custom_data['outcome'],\n",
    "    DifferenceInMeans,\n",
    "    n_bootstrap=100\n",
    ")\n",
    "\n",
    "print(\"Bootstrap results:\")\n",
    "print(f\"Mean ATE: {bootstrap_results['mean']:.4f}\")\n",
    "print(f\"Standard deviation: {bootstrap_results['std']:.4f}\")\n",
    "print(f\"95% CI: [{bootstrap_results['ci_lower']:.4f}, {bootstrap_results['ci_upper']:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize bootstrap distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bootstrap_results['estimates'], bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "plt.axvline(bootstrap_results['mean'], color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Mean = {bootstrap_results[\"mean\"]:.4f}')\n",
    "plt.axvline(true_ate, color='green', linestyle='-', linewidth=2, \n",
    "            label=f'True ATE = {true_ate:.4f}')\n",
    "plt.xlabel('Average Treatment Effect Estimate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Bootstrap Distribution of ATE Estimates')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c264cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comprehensive testing\n",
    "def test_estimator_convergence(estimator_class, sample_sizes=[100, 500, 1000, 2000], **kwargs):\n",
    "    results = []\n",
    "\n",
    "    for n in sample_sizes:\n",
    "        estimates = []\n",
    "        for i in range(10):  # Multiple runs per sample size\n",
    "            data_dict = generate_synthetic_data(n_samples=n, treatment_effect=2.0, random_state=i)\n",
    "            data = data_dict['data']\n",
    "            feature_names = data_dict['feature_names']\n",
    "\n",
    "            estimator = estimator_class(**kwargs)\n",
    "            estimator.fit(data[feature_names], data['treatment'], data['outcome'])\n",
    "            estimate = estimator.estimate_effect()\n",
    "            estimates.append(estimate)\n",
    "\n",
    "        results.append({\n",
    "            'n_samples': n,\n",
    "            'bias': np.mean(estimates) - 2.0,\n",
    "            'variance': np.var(estimates),\n",
    "            'mse': np.mean([(est - 2.0)**2 for est in estimates])\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Test convergence\n",
    "convergence_results = test_estimator_convergence(DifferenceInMeans)\n",
    "\n",
    "# Plot results\n",
    "sample_sizes = [r['n_samples'] for r in convergence_results]\n",
    "bias = [abs(r['bias']) for r in convergence_results]\n",
    "mse = [r['mse'] for r in convergence_results]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sample_sizes, bias, 'o-')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Absolute Bias')\n",
    "plt.title('Bias Convergence')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(sample_sizes, mse, 'o-')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE Convergence')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create results table\n",
    "results_df = pd.DataFrame(convergence_results)\n",
    "print(\"Convergence Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Testing Summary and Additional Issues Found\n",
    "\n",
    "During our comprehensive testing, we identified several additional issues:\n",
    "\n",
    "### New Issues:\n",
    "\n",
    "1. **Bootstrap Implementation**\n",
    "   - Current bootstrap doesn't stratify by treatment\n",
    "   - Can lead to imbalanced samples\n",
    "   - **Fix**: Implement stratified bootstrap\n",
    "\n",
    "2. **Cross-Validation Integration**\n",
    "   - Not integrated into main API\n",
    "   - **Fix**: Add CV support to CausalModel\n",
    "\n",
    "3. **Performance with Large Datasets**\n",
    "   - Poor scaling with dataset size\n",
    "   - **Fix**: Memory-efficient operations\n",
    "\n",
    "4. **API Extensions**\n",
    "   - No clear guidelines for custom estimators\n",
    "   - **Fix**: Add base classes and documentation\n",
    "\n",
    "### Testing Results:\n",
    "\n",
    "- All estimators show convergence to true effect with larger samples\n",
    "- Bootstrap provides good uncertainty estimation\n",
    "- Custom estimators can be easily integrated\n",
    "- Performance varies significantly across different scenarios\n"
   ],
   "id": "bc59c3b17cffa5e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Using CausalPilot Validation Utilities\n",
    "\n",
    "Before running advanced analyses, it's good practice to validate your synthetic dataset and any causal graph you construct. This helps catch issues like missing variables, graph cycles, or positivity violations.\n"
   ],
   "id": "5e7ada0a7e80ab4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Example: Validate synthetic data\n",
    "validation = validate_data(custom_data, 'treatment', 'outcome', feature_names)\n",
    "print(\"Data Validation:\")\n",
    "print(validation)\n",
    "\n",
    "# Example: Validate a simple graph\n",
    "G = cp.CausalGraph()\n",
    "G.add_nodes(['treatment', 'outcome'] + feature_names)\n",
    "G.add_edge('treatment', 'outcome')\n",
    "graph_validation = validate_graph(G)\n",
    "print(\"\\nGraph Validation:\")\n",
    "print(graph_validation)\n"
   ],
   "id": "a070c76cc361443a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Stratified Bootstrap for Unbiased Uncertainty Estimation\n",
    "\n",
    "The standard bootstrap may not preserve the treatment/control ratio, which can bias results. Here is a stratified bootstrap implementation:\n"
   ],
   "id": "6fe105320c2d5e24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def stratified_bootstrap_effect_estimation(X, T, Y, estimator_class, n_bootstrap=100, **kwargs):\n",
    "    treated_idx = T == 1\n",
    "    control_idx = T == 0\n",
    "    n_treated = treated_idx.sum()\n",
    "    n_control = control_idx.sum()\n",
    "    bootstrap_estimates = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        treated_sample = np.random.choice(np.where(treated_idx)[0], size=n_treated, replace=True)\n",
    "        control_sample = np.random.choice(np.where(control_idx)[0], size=n_control, replace=True)\n",
    "        indices = np.concatenate([treated_sample, control_sample])\n",
    "        X_boot = X.iloc[indices]\n",
    "        T_boot = T.iloc[indices]\n",
    "        Y_boot = Y.iloc[indices]\n",
    "        estimator = estimator_class(**kwargs)\n",
    "        estimator.fit(X_boot, T_boot, Y_boot)\n",
    "        ate = estimator.estimate_effect()\n",
    "        bootstrap_estimates.append(ate)\n",
    "    bootstrap_estimates = np.array(bootstrap_estimates)\n",
    "    return {\n",
    "        'estimates': bootstrap_estimates,\n",
    "        'mean': np.mean(bootstrap_estimates),\n",
    "        'std': np.std(bootstrap_estimates),\n",
    "        'ci_lower': np.percentile(bootstrap_estimates, 2.5),\n",
    "        'ci_upper': np.percentile(bootstrap_estimates, 97.5)\n",
    "    }\n",
    "\n",
    "# Run stratified bootstrap for custom estimator\n",
    "strat_bootstrap_results = stratified_bootstrap_effect_estimation(\n",
    "    custom_data[feature_names],\n",
    "    custom_data['treatment'],\n",
    "    custom_data['outcome'],\n",
    "    DifferenceInMeans,\n",
    "    n_bootstrap=100\n",
    ")\n",
    "\n",
    "print(\"Stratified Bootstrap results:\")\n",
    "print(f\"Mean ATE: {strat_bootstrap_results['mean']:.4f}\")\n",
    "print(f\"Standard deviation: {strat_bootstrap_results['std']:.4f}\")\n",
    "print(f\"95% CI: [{strat_bootstrap_results['ci_lower']:.4f}, {strat_bootstrap_results['ci_upper']:.4f}]\")\n"
   ],
   "id": "f84f3013a3f6ae35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Extending CausalPilot: Custom Estimators\n",
    "\n",
    "To add your own estimator to CausalPilot workflows, implement a class with fit, predict, and estimate_effect methods. See the DifferenceInMeans example above. You can then use your estimator in bootstrapping, cross-validation, or comparison routines.\n"
   ],
   "id": "5ef591c2127cbde3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Advanced Interpretation and Diagnostics\n",
    "\n",
    "- Always check the bias and variance of your estimator using convergence plots.\n",
    "- Use stratified bootstrap for more reliable confidence intervals.\n",
    "- Validate your data and graph before trusting results.\n",
    "- Large variation in individual effects suggests heterogeneityâ€”consider subgroup analysis.\n"
   ],
   "id": "10692671fa315c3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Troubleshooting and FAQ\n",
    "\n",
    "**Q: My bootstrap results are unstable.**\n",
    "- Increase the number of bootstrap samples. Use stratified bootstrap for binary treatments.\n",
    "\n",
    "**Q: My estimator fails on some samples.**\n",
    "- Check for empty treatment or control groups in your data splits.\n",
    "\n",
    "**Q: How do I add a new estimator?**\n",
    "- Implement fit, predict, and estimate_effect. See above for a template.\n",
    "\n",
    "**Q: How do I validate my data or graph?**\n",
    "- Use validate_data and validate_graph from causalpilot.utils.validation.\n"
   ],
   "id": "883871d78d3f54e3"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
